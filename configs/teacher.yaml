# Teacher configuration for data generation
# Controls which models to use, generation settings, and safety limits

# Model fallback chain (order matters)
# Try free models first, then paid models if fallback_to_paid=true
models:
  - meta-llama/llama-3.3-70b-instruct:free
  - deepseek/deepseek-chat-v3.1:free
  - openai/gpt-4o

# Generation parameters
generation:
  temperature: 0.2  # Low temperature for more deterministic/focused outputs
  top_p: 0.9        # Nucleus sampling
  max_tokens: 900   # Maximum response length
  seed: 42          # Random seed for reproducibility

# Runtime behavior
runtime:
  dry_run: true          # If true, skip actual API calls (for testing)
  timeout_s: 60          # Request timeout in seconds
  fallback_to_paid: true # If true, allow fallback to paid models; if false, stop at last free model

# Rate limiting and retry
rate_limit:
  rpm: 15                  # Requests per minute
  max_retries_per_model: 6 # Maximum retries per model before fallback
  backoff_base_s: 1.0      # Base backoff time in seconds
  backoff_max_s: 30.0      # Maximum backoff time in seconds

# Safety limits
safety:
  max_requests: 500         # Maximum total requests per run
  max_total_tokens: 2000000 # Maximum total tokens across all requests
